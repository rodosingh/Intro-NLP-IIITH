import sys
import gensim
import numpy as np
import pickle
from tqdm import tqdm
from collections import defaultdict as dd
from train_transMat import get_lexicalizations


def most_similar_vector(self, vectenter, topn=5):
	model_source.fill_norms()
	dists = np.dot(self.vectors, vectenter)
	if not topn:
		return dists
	best = np.argsort(dists)[::-1][:topn]
	result = [(self.index_to_key[sim], float(dists[sim])) for sim in best]
	return result[:topn]


def top_translations(w,translation_matrix,numb=5):
	vec_tm = translation_matrix.dot(model_target[w])
	norm_tm = vec_tm/np.linalg.norm(vec_tm)
	val = most_similar_vector(model_source,norm_tm,numb)
	return val


if __name__ == '__main__':
	args = sys.argv[1:]
	if len(args) >= 4:
		data = args[0]
		matrix_file = args[1]
		embeddings_model = args[2]
		top_candidates = int(args[3])
	if len(args) != 4 and len(args) != 5:
		sys.exit('You must provide four or five arguments. Check README file.')
	if bool(int(args[4])):
		print( 'Loading embeddings_model from pickle...')
		f = open("Loaded_vec.pkl", "rb")
		M = pickle.load(f)
		f.close()
	else:
		print("Loading embeddings_model via gensim")
	M = gensim.models.KeyedVectors.load_word2vec_format(embeddings_model, binary=False)
	M_vocab = M.index_to_key
	model_source = M
	model_target = M
	matrix = np.loadtxt(matrix_file)
	if expanded == 'expanded':
		syn_lex_dict = get_lexicalizations(M_vocab)
	outf = open(data+'_hypernyms.txt', 'w')
	missed_words = list()
	for concept in tqdm(open(data, 'r')):
		try:
			concept = concept.strip()
			res = top_translations(concept, matrix, numb=top_candidates)
			outf.write(concept+'\t'+'\t'.join([elm[0]+' '+str(elm[1]) for elm in res])+'\n')
		except BaseException as e:
			missed_words.append(concept)
			continue
	outf.close()
	# Check which words were missed.
	f = open("missed_words.txt", "wb")
	pickle.dump(missed_words, f)
	f.close()
